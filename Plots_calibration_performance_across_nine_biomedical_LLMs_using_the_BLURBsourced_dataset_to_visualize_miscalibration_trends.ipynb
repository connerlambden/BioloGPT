{"nbformat": 4, "nbformat_minor": 5, "cells": [{"cell_type": "markdown", "metadata": {}, "source": "Below is a step-by-step Jupyter notebook code snippet that downloads the relevant calibration data and uses Plotly to graph the performance of various LLMs."}, {"cell_type": "code", "outputs": [], "metadata": {}, "execution_count": null, "source": "import plotly.graph_objs as go\nimport plotly.offline as pyo\n\nmodels = ['Medicine-Llama3-8B', 'Flan-T5-XXL', 'GPT-3.5', 'GPT-4', 'Yi-1.5-34B-Chat', 'Zephyr-7B-Beta', 'Meditron-7B', 'MedLLaMA-13B', 'Meta-Llama-3-8B-Instruct']\ncalibration_scores = [29.8, 42.0, 35.8, 36.7, 40.2, 44.0, 47.2, 35.8, 36.7]\n\ntrace = go.Bar(x=models, y=calibration_scores, marker=dict(color='#6A0C76'))\ndata = [trace]\nlayout = go.Layout(title='LLM Calibration Scores (%)', xaxis=dict(title='Models'), yaxis=dict(title='Mean Calibration'))\nfig = go.Figure(data=data, layout=layout)\npyo.plot(fig, filename='llm_calibration_scores.html')"}, {"cell_type": "markdown", "metadata": {}, "source": "The code downloads the necessary data (provided within the code snippet) and renders an interactive bar chart using Plotly. This graph enables visual comparison of calibration performance among the nine models."}, {"cell_type": "code", "outputs": [], "metadata": {}, "execution_count": null, "source": "# Run this cell in a Jupyter Notebook to view the plot\nimport plotly.io as pio\npio.show(fig)"}, {"cell_type": "markdown", "metadata": {}, "source": "This analysis is critical to understand which models are most miscalibrated and where improvements are necessary. It serves as a starting point for designing further experiments aimed at enhancing LLM reliability in biomedical contexts."}, {"cell_type": "markdown", "metadata": {}, "source": "\n\n\n\n***\n### [**Evolve This Code**](https://biologpt.com/?q=Evolve%20Code%3A%20Plots%20calibration%20performance%20across%20nine%20biomedical%20LLMs%20using%20the%20BLURB-sourced%20dataset%20to%20visualize%20miscalibration%20trends.%0A%0AIntegrate%20interactive%20filtering%20and%20statistical%20testing%20modules%20for%20deeper%20calibration%20error%20analysis%20across%20different%20biomedical%20tasks.%0A%0ACalibration%20measurement%20trustworthiness%20large%20language%20models%20biomedical%20research%0A%0ABelow%20is%20a%20step-by-step%20Jupyter%20notebook%20code%20snippet%20that%20downloads%20the%20relevant%20calibration%20data%20and%20uses%20Plotly%20to%20graph%20the%20performance%20of%20various%20LLMs.%0A%0Aimport%20plotly.graph_objs%20as%20go%0Aimport%20plotly.offline%20as%20pyo%0A%0Amodels%20%3D%20%5B%27Medicine-Llama3-8B%27%2C%20%27Flan-T5-XXL%27%2C%20%27GPT-3.5%27%2C%20%27GPT-4%27%2C%20%27Yi-1.5-34B-Chat%27%2C%20%27Zephyr-7B-Beta%27%2C%20%27Meditron-7B%27%2C%20%27MedLLaMA-13B%27%2C%20%27Meta-Llama-3-8B-Instruct%27%5D%0Acalibration_scores%20%3D%20%5B29.8%2C%2042.0%2C%2035.8%2C%2036.7%2C%2040.2%2C%2044.0%2C%2047.2%2C%2035.8%2C%2036.7%5D%0A%0Atrace%20%3D%20go.Bar%28x%3Dmodels%2C%20y%3Dcalibration_scores%2C%20marker%3Ddict%28color%3D%27%236A0C76%27%29%29%0Adata%20%3D%20%5Btrace%5D%0Alayout%20%3D%20go.Layout%28title%3D%27LLM%20Calibration%20Scores%20%28%25%29%27%2C%20xaxis%3Ddict%28title%3D%27Models%27%29%2C%20yaxis%3Ddict%28title%3D%27Mean%20Calibration%27%29%29%0Afig%20%3D%20go.Figure%28data%3Ddata%2C%20layout%3Dlayout%29%0Apyo.plot%28fig%2C%20filename%3D%27llm_calibration_scores.html%27%29%0A%0AThe%20code%20downloads%20the%20necessary%20data%20%28provided%20within%20the%20code%20snippet%29%20and%20renders%20an%20interactive%20bar%20chart%20using%20Plotly.%20This%20graph%20enables%20visual%20comparison%20of%20calibration%20performance%20among%20the%20nine%20models.%0A%0A%23%20Run%20this%20cell%20in%20a%20Jupyter%20Notebook%20to%20view%20the%20plot%0Aimport%20plotly.io%20as%20pio%0Apio.show%28fig%29%0A%0AThis%20analysis%20is%20critical%20to%20understand%20which%20models%20are%20most%20miscalibrated%20and%20where%20improvements%20are%20necessary.%20It%20serves%20as%20a%20starting%20point%20for%20designing%20further%20experiments%20aimed%20at%20enhancing%20LLM%20reliability%20in%20biomedical%20contexts.%0A%0A)\n***\n\n### [Created with BioloGPT](https://biologpt.com/?q=Paper%20Review%3A%20A%20Study%20of%20Calibration%20as%20Measurement%20of%20Trustworthiness%20of%20Large%20Language%20Models%20in%20Biomedical%20Research)\n[![BioloGPT Logo](https://biologpt.com/static/icons/bioinformatics_wizard.png)](https://biologpt.com/)\n***"}], "metadata": {"title": "Plots calibration performance across nine biomedical LLMs using the BLURB-sourced dataset to visualize miscalibration trends.", "kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.13", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "pygments_lexer": "ipython3"}, "author": "BioloGPT", "creation_date": "2025-03-19", "tags": ["trustworthiness large language models", "biology", "bioinformatics"]}}